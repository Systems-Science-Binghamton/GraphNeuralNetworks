{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82ef417a",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "In this assignment, we will use the Cora citation network. Each node represents a paper, and each edge from node $i$ to $j$ represents the citation from $i$ to $j$. A field code is assigned to individual paper, which is in the `field` column in the node table.\n",
    "We will ignore the edge directionality and apply a graph embedding to the undirected network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80173d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "node_table = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/skojaku/adv-net-sci-course/main/data/cora/node_table.csv\"\n",
    ")\n",
    "edge_table = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/skojaku/adv-net-sci-course/main/data/cora/edge_table.csv\",\n",
    "    dtype={\"src\": np.int32, \"trg\": np.int32},\n",
    ")\n",
    "src, trg = tuple(edge_table[[\"src\", \"trg\"]].values.T)\n",
    "\n",
    "rows, cols = src, trg\n",
    "nrows, ncols = node_table.shape[0], node_table.shape[0]\n",
    "A = sparse.csr_matrix(\n",
    "    (np.ones_like(rows), (rows, cols)),\n",
    "    shape=(nrows, ncols),\n",
    ").asfptype()\n",
    "\n",
    "# Symmterize and binarize\n",
    "A = A + A.T\n",
    "A.data = A.data * 0 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c5f018",
   "metadata": {},
   "source": [
    "---\n",
    "**Question 1: Implement the node2vec algorithm.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f0659f",
   "metadata": {},
   "source": [
    "First, let's prepare a function to generate node sequences with random walks on networks. Since simulating random walks can be a considerable bottleneck, we prepare the function for you to use. Notice that the function takes `indptr` and `indices` of the CSR representation of the adjacency matrix instead of the adjacency matrix itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f141730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "\n",
    "\n",
    "@njit(cache=True, nogil=True)\n",
    "def random_walk(indices, indptr, start_node_id, walk_length):\n",
    "    \"\"\"Random walk on a graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    indices : numpy.ndarray\n",
    "        CSR matrix indices.\n",
    "    indptr : numpy.ndarray\n",
    "        CSR matrix indptr.\n",
    "    start_node_id : int\n",
    "        Id of the starting node.\n",
    "    walk_length : int\n",
    "        Length of the walk.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    visited_nodes : list\n",
    "        List of visited nodes.\n",
    "    \"\"\"\n",
    "    visited_nodes = [start_node_id]\n",
    "    current_node_id = start_node_id\n",
    "\n",
    "    for _ in range(walk_length):\n",
    "        # Get the neighbors of the current node\n",
    "        # Hint: Use A.indices and A.indptr\n",
    "        neighbors = indices[indptr[current_node_id] : indptr[current_node_id + 1]]\n",
    "\n",
    "        if len(neighbors) == 0:\n",
    "            break\n",
    "        current_node_id = np.random.choice(neighbors)\n",
    "        visited_nodes.append(current_node_id)\n",
    "\n",
    "    return visited_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacfa1ad",
   "metadata": {},
   "source": [
    "Now, let's implement the node2vec algorithm. Here is a template for the class. Implement the node2vec algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af95ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "\n",
    "class SimpleNode2Vec:\n",
    "    def __init__(self, window_length=5, n_walkers=10, walk_length=40):\n",
    "        \"\"\"Node2Vec class\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        p : float\n",
    "          Walk bias parameter\n",
    "        q : float\n",
    "          In-out parameter\n",
    "        \"\"\"\n",
    "        # set this to `window` parameter of word2vec in `def emb()` funcion\n",
    "        self.window_length = window_length\n",
    "\n",
    "        # These are the parameters for random walks\n",
    "        self.n_walkers = n_walkers  # Number of walkers per node\n",
    "        self.walk_length = walk_length  # window length\n",
    "\n",
    "    def embed(self, A, dim):\n",
    "        \"\"\"Embed nodes in a graph\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        A : scipy sparse matrix\n",
    "          Adjacency matrix\n",
    "        dim : int\n",
    "          Dimension of embeddings\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        emb : numpy array (n_nodes, dim)\n",
    "          Embeddings\n",
    "        \"\"\"\n",
    "\n",
    "        # Your code to generate embeddings\n",
    "\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090f2e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "# Test\n",
    "def test_node2vec():\n",
    "    # Test with karate club\n",
    "    G = nx.karate_club_graph()\n",
    "    A = nx.adjacency_matrix(G)\n",
    "    labels = np.unique([d[1][\"club\"] for d in G.nodes(data=True)], return_inverse=True)[\n",
    "        1\n",
    "    ]\n",
    "\n",
    "    # Embedding\n",
    "    n2v = SimpleNode2Vec()\n",
    "    emb = n2v.embed(A, dim=64)\n",
    "\n",
    "    clf = LinearDiscriminantAnalysis(n_components=1)\n",
    "    clf.fit(emb, labels)\n",
    "    assert emb.shape == (A.shape[0], 64)\n",
    "    assert clf.score(emb, labels) > 0.8\n",
    "\n",
    "\n",
    "test_node2vec()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dea551",
   "metadata": {},
   "source": [
    "**Question 2: Visualize the 64 dimensional embedding of the cora network by using UMAP**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e169f4a",
   "metadata": {},
   "source": [
    "First, let's generate the embedding of the cora network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d448c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = SimpleNode2Vec().embed(A, dim=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28099eb0",
   "metadata": {},
   "source": [
    "Then, write a code to generate an embedding based on the UMAP. You can use any parameter for UMAP. Here is a suggested set of parameters: n_components=2, random_state=42, n_neighbors=30, min_dist=0.8, metric = \"cosine.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b29c2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Your code here ---\n",
    "x = ...\n",
    "y = ...\n",
    "# --- End of your code ---\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "sns.set(font_scale=1.2)\n",
    "sns.set_style(\"ticks\")\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "\n",
    "labels = node_table[\"field\"].values\n",
    "ax = sns.scatterplot(x=x, y=y, hue=labels, ax=ax)\n",
    "\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)\n",
    "ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde1b479",
   "metadata": {},
   "source": [
    "Color represents the regions, and the size of the nodes represents the degree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7402f8f8",
   "metadata": {},
   "source": [
    "---\n",
    "**Question 3**\n",
    "\n",
    "\n",
    "**Preparation:**\n",
    "Suppose a task of classifying papers into fields based on the citation network structure. Our classifier will take the graph embedding and predict its field. You are given the field labels for 80% of the papers. And the task is to classify the remaining 20\\% of the papers.\n",
    "\n",
    "First, we will reserve 80% of the data for training and the remaining 20% for evaluating the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74242a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the node table into the train and test set.\n",
    "df = node_table.sample(frac=1, random_state=0)\n",
    "train_node_table = df.iloc[: int(len(df) * 0.8)]\n",
    "test_node_table = df.iloc[int(len(df) * 0.2) :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfef0121",
   "metadata": {},
   "source": [
    "We will evaluate the classification performance by the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8aa991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_prediction_accuracy(y, yred):\n",
    "    \"\"\"Calculate prediction accuracy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : numpy.ndarray\n",
    "      True labels.\n",
    "    ypred : numpy.ndarray\n",
    "      Predicted labels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    acc : float\n",
    "      Prediction accuracy.\n",
    "    \"\"\"\n",
    "    return np.sum(y == yred) / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f211f0",
   "metadata": {},
   "source": [
    "We will use the Support Vector Machine implemented in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306130a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c568ea16",
   "metadata": {},
   "source": [
    "Here are how we test the accuracy of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48afafe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "clf = SVC()\n",
    "clf.fit(emb[train_node_table[\"node_id\"].values], train_node_table[\"field\"].values)\n",
    "\n",
    "# Predict\n",
    "ypred = clf.predict(emb[test_node_table[\"node_id\"].values])\n",
    "\n",
    "# Evaluation\n",
    "accuracy = eval_prediction_accuracy(ypred, test_node_table[\"field\"].values)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de229ab",
   "metadata": {},
   "source": [
    "**Question: Draw a line plot for the accuracy as a function of the embedding dimension $K$. Test $K=2,4,8,16,32,64,128,256$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93da2db7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "206c5531",
   "metadata": {},
   "source": [
    "You should see that the accuracy stays relatively high even if we increase the dimensions. This is clearly a different behavior from the spectral embedding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advnetsci",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
