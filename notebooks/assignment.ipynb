{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be19361c",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "In this assignment, we will use the Cora citation network. Each node represents a paper, and each edge from node $i$ to $j$ represents the citation from $i$ to $j$. A field code is assigned to an individual paper, which is in the `field` column in the node table.\n",
    "We will ignore the edge directionality and apply a graph embedding to the undirected network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b953f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "node_table = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/skojaku/adv-net-sci-course/main/data/cora/node_table.csv\"\n",
    ")\n",
    "node_feature_table = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/skojaku/adv-net-sci-course/main/data/cora/node_features.csv\"\n",
    ")\n",
    "edge_table = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/skojaku/adv-net-sci-course/main/data/cora/edge_table.csv\",\n",
    "    dtype={\"src\": np.int32, \"trg\": np.int32},\n",
    ")\n",
    "src, trg = tuple(edge_table[[\"src\", \"trg\"]].values.T)\n",
    "\n",
    "rows, cols = src, trg\n",
    "nrows, ncols = node_table.shape[0], node_table.shape[0]\n",
    "A = sparse.csr_matrix(\n",
    "    (np.ones_like(rows), (rows, cols)),\n",
    "    shape=(nrows, ncols),\n",
    ").asfptype()\n",
    "\n",
    "# Symmterize and binarize\n",
    "A = A + A.T\n",
    "A.data = A.data * 0 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21ae0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node features\n",
    "node_features = node_feature_table.drop(columns=[\"node_id\"]).values\n",
    "\n",
    "# Node labels (field)\n",
    "node_labels = node_table[\"field\"].values  # Raw labels (str)\n",
    "node_label_ids = np.unique(node_labels, return_inverse=True)[1]  # Integer labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08067abc",
   "metadata": {},
   "source": [
    "Additionally, we create a PyTorch version of the sparse matrix: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3c3cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this function to convert scipy sparse matrix to torch sparse matrix\n",
    "def to_torch_sparse(A):\n",
    "    \"\"\"Convert scipy sparse matrix to torch sparse matrix\"\"\"\n",
    "    Atorch = torch.sparse_csr_tensor(A.indptr, A.indices, A.data, dtype=torch.float32)\n",
    "    return Atorch\n",
    "\n",
    "\n",
    "Atorch = to_torch_sparse(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363ba0ed",
   "metadata": {},
   "source": [
    "---\n",
    "**Question 1: Implement the graph convolutional layer (Eq. 2 in [the paper](https://openreview.net/pdf?id=SJU4ayYgl) with [ReLu activation](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) $\\sigma$) by using pytorch, numpy, and scipy.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40b2e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear, LeakyReLU, Softmax\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "\n",
    "class GraphConv(torch.nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, A):\n",
    "    \"\"\"Graph Convolution Layer\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : int\n",
    "     Input dimension\n",
    "    out_channels : int\n",
    "     Output dimension\n",
    "    A : scipy.csr_matrix (n_nodes, n_nodes)\n",
    "     Adjacency matrix\n",
    "    \"\"\"\n",
    "    super(GraphConv, self).__init__()\n",
    "    # Your code ----\n",
    "    self.conv_mat = ...\n",
    "    self.linear = ...\n",
    "    self.act = ...\n",
    "    # --------------\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\"Forward pass\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : torch.Tensor (n_nodes, in_channels)\n",
    "     Input node features\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor (n_nodes, out_channels)\n",
    "     Output node features\n",
    "    \"\"\"\n",
    "\n",
    "    # Your code ----\n",
    "    z = ...\n",
    "    # --------------\n",
    "\n",
    "    return z\n",
    "\n",
    "\n",
    "# Test\n",
    "def test_GCN():\n",
    "  GraphConv(100, 50, A)\n",
    "\n",
    "\n",
    "test_GCN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb685b1d",
   "metadata": {},
   "source": [
    "---\n",
    "**Question 2: Implement the Graph Convolutional Network by using the GCNLayer implemented above. Use at least one GCN layer, and the last layer must be the softmax layer.**\n",
    "\n",
    "\n",
    "**Implementation guideline:**\n",
    "\n",
    "You can implement any GCN architecture that involves at least one GCNLayer. Here is an example of GCN's architecture. \n",
    "\n",
    "1. This GCN starts with graph convolutional layers, which perform two convolutional operations on the input node feature vectors. The first graph convolutional layer transforms feature vectors from `in_channel` dimensions to `hidden_channel` dimensions, and the second convolution layer transforms the `hidden_channel` dimensional vector to `out_channel` dimensional vectors. (Apply two GCNLayer implemented above) \n",
    "2. After performing two convolutional operations, a linear layer is applied. This linear layer transforms `out_channel` dimensional vector to `out_channel` dimensional vector (Apply torch.nn.Linear). \n",
    "3. Finally, a soft-max layer is applied to transform the `out_channel` dimensional vector to `out_channel` vector representing a probability distribution over the output classes. The softmax function ensures that the output of the network can be interpreted as probabilities and that these probabilities sum to 1 (Apply torch.nn.Softmax). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17156ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear, LeakyReLU, Softmax\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "\n",
    "class GraphConv(torch.nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, A):\n",
    "    \"\"\"Graph Convolution Layer\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : int\n",
    "     Input dimension\n",
    "    out_channels : int\n",
    "     Output dimension\n",
    "    A : scipy.csr_matrix (n_nodes, n_nodes)\n",
    "     Adjacency matrix\n",
    "    \"\"\"\n",
    "    super(GraphConv, self).__init__()\n",
    "    self.linear = Linear(in_channels, out_channels)\n",
    "    self.act = LeakyReLU()\n",
    "    Ahat = sparse.eye(A.shape[0]) + A\n",
    "    indeg = np.array(Ahat.sum(axis=0)).reshape(-1)\n",
    "    indeg_sqrt_inv = np.power(indeg, -0.5)\n",
    "    Lhat = sparse.diags(indeg_sqrt_inv) @ Ahat @ sparse.diags(indeg_sqrt_inv)\n",
    "    self.conv_mat = to_torch_sparse(Lhat)\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\"Forward pass\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : torch.Tensor (n_nodes, in_channels)\n",
    "     Input node features\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor (n_nodes, out_channels)\n",
    "     Output node features\n",
    "    \"\"\"\n",
    "\n",
    "    # Your code ----\n",
    "    z = self.linear(x)\n",
    "    z = self.conv_mat @ z\n",
    "    z = self.act(z)\n",
    "    # --------------\n",
    "\n",
    "    return z\n",
    "\n",
    "\n",
    "# Test\n",
    "def test_GCN():\n",
    "  GraphConv(100, 50, A)\n",
    "\n",
    "\n",
    "test_GCN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d681996",
   "metadata": {},
   "source": [
    "---\n",
    "**Question 3**\n",
    "\n",
    "\n",
    "**Preparation:**\n",
    "Suppose a task of classifying papers into fields based on the citation network structure and *node features*. You are given the field labels for 80% of the papers. And the task is to classify the remaining 20\\% of the papers.\n",
    "\n",
    "First, we will reserve 80% of the data for training and the remaining 20% for evaluating the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9ed826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the node table into the train and test set.\n",
    "df = node_table.sample(frac=1, random_state=0)\n",
    "train_node_table = df.iloc[: int(len(df) * 0.8)]\n",
    "test_node_table = df.iloc[int(len(df) * 0.2) :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e52765",
   "metadata": {},
   "source": [
    "We will evaluate the classification performance by the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eaceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_prediction_accuracy(y, yred):\n",
    "    \"\"\"Calculate prediction accuracy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : numpy.ndarray\n",
    "     True labels.\n",
    "    ypred : numpy.ndarray\n",
    "     Predicted labels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    acc : float\n",
    "     Prediction accuracy.\n",
    "    \"\"\"\n",
    "    return float(np.sum(y == yred)) / float(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27a14cd",
   "metadata": {},
   "source": [
    "We will use the GCN implemented above for classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40e079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = len(np.unique(node_labels))\n",
    "\n",
    "in_channel = node_features.shape[1]\n",
    "hidden_channel = 100\n",
    "out_channel = n_labels\n",
    "model = GCN(\n",
    "    in_channel=in_channel, hidden_channel=hidden_channel, out_channel=out_channel, A=A\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb7b20",
   "metadata": {},
   "source": [
    "Here is how we train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93575ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# Define training loop\n",
    "def train(model, optimizer, criterion, x_train, y_train, A, train_mask):\n",
    "    \"\"\"Train the model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "     Model\n",
    "    optimizer : torch.optim.Optimizer\n",
    "      Optimizer\n",
    "    criterion : torch.nn.modules.loss._Loss\n",
    "      Loss function\n",
    "    x_train : torch.Tensor (n_nodes, in_channels)\n",
    "      Input node features\n",
    "    y_train : torch.Tensor (n_nodes)\n",
    "      True labels\n",
    "    A : scipy.sparse.csr_matrix (n_nodes, n_nodes)\n",
    "      Adjacency matrix\n",
    "    train_mask : numpy.ndarray\n",
    "      Mask for training nodes\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss.item() : float\n",
    "      Loss value\n",
    "    \"\"\"\n",
    "\n",
    "    # Reset gradient\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(x_train)\n",
    "\n",
    "    # Only compute loss for nodes in the training set\n",
    "    loss = criterion(output[train_mask, :], y_train[train_mask])\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # Return loss\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Find the indices of the train and test nodes\n",
    "train_mask = np.array(train_node_table[\"node_id\"])\n",
    "test_mask = np.array(test_node_table[\"node_id\"])\n",
    "\n",
    "# Convert numpy arrays to torch tensors\n",
    "X = torch.FloatTensor(node_features)\n",
    "Y = torch.LongTensor(node_label_ids)\n",
    "\n",
    "# Number of epochs to train\n",
    "n_epochs = 500\n",
    "pbar = tqdm(range(n_epochs))\n",
    "\n",
    "# Train the model\n",
    "model.train()\n",
    "for epoch in pbar:\n",
    "    loss = train(model, optimizer, criterion, X, Y, Atorch, train_mask)\n",
    "    pbar.set_description(f\"Epoch {epoch+1}, Loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cc7e59",
   "metadata": {},
   "source": [
    "**Task: Generate the prediction using the trained model and evaluate the accuracy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f514bfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "\n",
    "# Your code ----\n",
    "# Hint\n",
    "# output = ...\n",
    "# ypred = ... # output gives a probability distribution over classes. Pick the one with the highest probability.\n",
    "# --------------\n",
    "\n",
    "acc = eval_prediction_accuracy(Y[test_mask].numpy(), ypred[test_mask])\n",
    "print(f\"Test accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12b018b",
   "metadata": {},
   "source": [
    "**Question 4: Train the GCN with random feature vectors generated from a Gaussian distribution and perform the classification.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac167d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features_random = np.random.randn(node_table.shape[0], 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f59fe3f",
   "metadata": {},
   "source": [
    "And reset the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1a936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channel = node_features_random.shape[1]\n",
    "hidden_channel = 100\n",
    "out_channel = n_labels\n",
    "model = GCN(\n",
    "    in_channel=in_channel, hidden_channel=hidden_channel, out_channel=out_channel, A=A\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff161a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code ----\n",
    "\n",
    "# --------------\n",
    "acc = eval_prediction_accuracy(Y[test_mask].numpy(), ypred[test_mask])\n",
    "print(f\"Test accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6dcd49",
   "metadata": {},
   "source": [
    "You should see that performance decreases. The difference in performance compared to the GCN with raw node features is attributed to the utilization of node features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advnetsci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
